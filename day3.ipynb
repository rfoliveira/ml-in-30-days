{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ffb3c88",
   "metadata": {},
   "source": [
    "# Understanding data and preprocessing\n",
    "## Types of data: strutured and unstructured\n",
    "\n",
    "<u>Structured data</u>\n",
    "\n",
    "Structured data refers to information that is organized in a fixed format, typically in tables, spreadsheets, or relational databases. It follows a predefined schema with rows and columns, making it easy to store, query, and analyze using database management systems and analytical tools. \n",
    "\n",
    "Examples of structured data: \n",
    "- Customer transaction records in a retail store  \n",
    "- Employee databases containing names, salaries, and job titles  \n",
    "- Financial statements showing revenues and expenses\n",
    "\n",
    "Structured data is advantageous for machine learning as it can be easily manipulated using programming languages like Python, SQL, and libraries such as Pandas and NumPy.\n",
    "\n",
    "<u>Unstructured data</u>\n",
    "\n",
    "Unstructured data, on the other hand, lacks a predefined format and does not fit neatly into tables or relational databases. It includes text, images, audio, and video files. Processing unstructured data requires specialized techniques, including natural language processing (NLP) for text, computer vision for images, and speech recognition for audio. \n",
    "\n",
    "Examples of unstructured data: \n",
    "\n",
    "- Social media posts, emails, and chat messages  \n",
    "- Medical imaging scans such as X-rays and MRIs  \n",
    "- Audio recordings and speech transcriptions  \n",
    "- Handling unstructured data often involves feature extraction and transformation techniques to convert the raw data into a structured format suitable for machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72971b10",
   "metadata": {},
   "source": [
    "## Handling missing data\n",
    "\n",
    "In real-world datasets, missing values are a common issue and must be handled carefully to prevent bias or inaccurate predictions. There are several techniques to deal with missing data, depending on the context and severity of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3fef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. removing missing data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv')\n",
    "df_cleaned = df.dropna()    # remove rows with missing values\n",
    "\n",
    "# 2. imputation (filling missing values)\n",
    "# Instead of removing missing data, we can fill in the gaps with meaningful values. \n",
    "# This can be done using:  \n",
    "# - Mean or median imputation for numerical data  \n",
    "# - Mode (most frequent value) for categorical data  \n",
    "# - Forward fill (using previous values) or backward fill (using next values) for time-series data\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)  # fill missing ages with the mean\n",
    "\n",
    "# 3. Using Machine Learning Models for Imputation: \n",
    "# In some cases, missing values can be predicted using machine learning models trained on existing data. \n",
    "# Algorithms such as k-nearest neighbors (KNN) or regression models can estimate missing values based on known patterns.\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9977c1cb",
   "metadata": {},
   "source": [
    "## Data cleaning and transformation\n",
    "\n",
    "Once missing values are handled, further data cleaning and transformation steps are necessary to prepare the dataset for machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fab9be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates\n",
    "# df.drop_duplicates(inplace=True)    # Do not use \"inplace=True\" when modifying a dataframe.sonarqube(ipython:S6734)\n",
    "df.drop_duplicates()\n",
    "\n",
    "# Handling Outliers \n",
    "# Outliers are extreme values that deviate significantly from the dataset's overall distribution. \n",
    "# Outliers can skew model predictions and should be treated appropriately.\n",
    "import numpy as np\n",
    "z_scores = np.abs((df['Salary']-df['Salary'].mean()) / df['Salary'].std())\n",
    "df_no_outliers = df[z_scores < 3]  # Keeping values within 3 standard deviations\n",
    "\n",
    "# Encoding Categorical Data\n",
    "# Machine learning algorithms require numerical input, so categorical data must be converted into numerical format.\n",
    "# Two common encoding techniques are:\n",
    "# - One-hot encoding (for nominal categorical variables, where no order exists)\n",
    "df = pd.get_dummies(df, columns=['Gender']) # Converts 'Male'and 'Female' into binary columns\n",
    "# - Label encoding (for ordinal categorical variables, where order matters)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df['Education_Level'] = encoder.fit_transform(df['Education_Level'])  # Converts 'High School', 'Bachelor's', etc. into numerical values\n",
    "\n",
    "# Feature Scaling\n",
    "# Feature scling ensures that numerical variables are in the same range, preventing features with larger values from dominating the learning process.\n",
    "# Two common techniques are:\n",
    "# - Standardization (z-score normalization)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# - Min-Max Scaling (rescaling values between 0 and 1)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "df_scaled = min_max_scaler.fit_transform(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab33e59",
   "metadata": {},
   "source": [
    "## Example: Filling missing values in a dataset using Pandas\n",
    "\n",
    "Let's consider an example where we load a dataset, identify missing values, and use imputation techniques to fill in the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a12dc891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "      Name   Age   Salary\n",
      "0    Alice  25.0  50000.0\n",
      "1      Bob   NaN  60000.0\n",
      "2  Charlie  30.0      NaN\n",
      "3    David   NaN  80000.0\n",
      "4      Eve  40.0  90000.0\n",
      "\n",
      "Dataset after filling missing values:\n",
      "      Name        Age   Salary\n",
      "0    Alice  25.000000  50000.0\n",
      "1      Bob  31.666667  60000.0\n",
      "2  Charlie  30.000000  70000.0\n",
      "3    David  31.666667  80000.0\n",
      "4      Eve  40.000000  90000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_7852\\2380565778.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_7852\\2380565778.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Salary'].fillna(df['Salary'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a sample dataset with missing values\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Age': [25, np.nan, 30, np.nan,40],\n",
    "    'Salary': [50000, 60000, np.nan, 80000, 90000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original Dataset:\")\n",
    "print(df)\n",
    "\n",
    "# Filling missing values with the mean of respective columns\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "df['Salary'].fillna(df['Salary'].mean(), inplace=True)\n",
    "\n",
    "print(\"\\nDataset after filling missing values:\")\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
